{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Intro \u00b6 These are not, the greatest docs in the World this is just a Playground Welcome to the Docs of my DevOps / GitHub / Jira - Playground. I decided to host them on GitHub-Pages via MkDocs-Material . Tools/Frameworks \u00b6 I used a combination of these tools and frameworks to have a useful playground I can experiment with: GitHub to host repositories Azure-DevOps to run the yaml pipelines Jira to manage issues MkDocs-Material to host versionable documentation DevOpsBuildAgent a containerized DevOps-Agent coming soon \u00b6 FastAPI since deploying an api could be useful Jfrog-Platform for artifacts like pip, containers, ... Expectations \u00b6 You should try to keep your expectations low, then you will be amazed even more while finding out about the things I am just finding out myself with this playground. graph LR; You[You] -->|when found<br>this Page| expectation{Expectations}; expectation{Expectations} -->|Low| Amazed(surely Amazed ); expectation{Expectations} -->|High| Disappointed(maybe Disappointed); Current Config \u00b6 This is the YAML file which was used to Configure the website you are currently viewing. mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 site_name : Azure-Pipelines with GitHub-Repo site_url : https://mauwii.github.io/azure-pipelines-with-github-repo/ dev_addr : 127.0.0.1:8000 site_author : mauwii site_description : >- ...to my playground, which was originally created to find out more about the possibilities when using GitHub-Repos with Azure-DevOps to run YAML based Azure-Pipelines, as well as the differences compared to the use of Azure-Repos. Meanwhile I also begun using Jira to track Issues and Features and it's integrated Service-Desk to have a Place for Bug reports or feature suggestions. Feel free to compare it to the newly available GitHub Issue Templates, which imho are also a very good approach when you need to support your user base. I also started to play around with Jfrog's Artifactory which is a great option to find vulnerabilities or supply container images, to name just a few of it's features. So as u see, there is already a lot going on here and it's not getting boring at all # Repository repo_name : Mauwii/azure-pipelines-with-github-repo repo_url : https://github.com/Mauwii/azure-pipelines-with-github-repo edit_uri : edit/main/docs/ # Copyright copyright : Copyright &copy; 2022 Matthias Wild # Configuration theme : name : null custom_dir : 'src/mkdocs-material/material' # 404 page static_templates : - 404.html # Necessary for search to work properly include_search_page : false search_index_only : true # Default values, taken from mkdocs_theme.yml language : en features : - content.code.annotate # - content.tabs.link - content.tooltips # - header.autohide - navigation.expand - navigation.indexes - navigation.instant - navigation.sections - navigation.tabs - navigation.tabs.sticky - navigation.top - navigation.tracking - search.highlight - search.share - search.suggest # - toc.follow - toc.integrate palette : - media : '(prefers-color-scheme: light)' primary : blue scheme : default toggle : icon : material/lightbulb name : Switch to dark mode - media : '(prefers-color-scheme: dark)' primary : dark-blue accent : white scheme : slate toggle : icon : material/lightbulb-outline name : Switch to light mode font : text : Roboto code : Roboto Mono favicon : 'assets/favicon.png' icon : logo : 'material/library' admonition : note : octicons/tag-16 abstract : octicons/checklist-16 info : octicons/info-16 tip : octicons/squirrel-16 success : octicons/check-16 question : octicons/question-16 warning : octicons/alert-16 failure : octicons/x-circle-16 danger : octicons/zap-16 bug : octicons/bug-16 example : octicons/beaker-16 quote : octicons/quote-16 # Customization extra : social : - icon : fontawesome/brands/github-alt link : https://github.com/Mauwii - icon : fontawesome/brands/docker link : https://hub.docker.com/r/mauwii/ - icon : fontawesome/brands/keybase link : https://keybase.io/mauwi - icon : material/email-fast link : mailto:mauwii@outlook.de version : provider : mike # Extensions markdown_extensions : - abbr - admonition - attr_list - def_list - footnotes - meta - md_in_html - toc : permalink : true - pymdownx.arithmatex : generic : true - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.details - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg - pymdownx.highlight : anchor_linenums : true - pymdownx.inlinehilite - pymdownx.keys - pymdownx.magiclink : repo_url_shorthand : true user : 'Mauwii' repo : 'azure-pipelines-with-github-repo' - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format - pymdownx.snippets - pymdownx.tabbed : alternate_style : true - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde - tables # Plugins plugins : - search - git-revision-date - mike License \u00b6 License Copyright \u00a9 2022 Matthias Wild Mauwii@outlook.de Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Home"},{"location":"#intro","text":"These are not, the greatest docs in the World this is just a Playground Welcome to the Docs of my DevOps / GitHub / Jira - Playground. I decided to host them on GitHub-Pages via MkDocs-Material .","title":"Intro"},{"location":"#toolsframeworks","text":"I used a combination of these tools and frameworks to have a useful playground I can experiment with: GitHub to host repositories Azure-DevOps to run the yaml pipelines Jira to manage issues MkDocs-Material to host versionable documentation DevOpsBuildAgent a containerized DevOps-Agent","title":"Tools/Frameworks"},{"location":"#coming-soon","text":"FastAPI since deploying an api could be useful Jfrog-Platform for artifacts like pip, containers, ...","title":"coming soon"},{"location":"#expectations","text":"You should try to keep your expectations low, then you will be amazed even more while finding out about the things I am just finding out myself with this playground. graph LR; You[You] -->|when found<br>this Page| expectation{Expectations}; expectation{Expectations} -->|Low| Amazed(surely Amazed ); expectation{Expectations} -->|High| Disappointed(maybe Disappointed);","title":"Expectations"},{"location":"#current-config","text":"This is the YAML file which was used to Configure the website you are currently viewing. mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 site_name : Azure-Pipelines with GitHub-Repo site_url : https://mauwii.github.io/azure-pipelines-with-github-repo/ dev_addr : 127.0.0.1:8000 site_author : mauwii site_description : >- ...to my playground, which was originally created to find out more about the possibilities when using GitHub-Repos with Azure-DevOps to run YAML based Azure-Pipelines, as well as the differences compared to the use of Azure-Repos. Meanwhile I also begun using Jira to track Issues and Features and it's integrated Service-Desk to have a Place for Bug reports or feature suggestions. Feel free to compare it to the newly available GitHub Issue Templates, which imho are also a very good approach when you need to support your user base. I also started to play around with Jfrog's Artifactory which is a great option to find vulnerabilities or supply container images, to name just a few of it's features. So as u see, there is already a lot going on here and it's not getting boring at all # Repository repo_name : Mauwii/azure-pipelines-with-github-repo repo_url : https://github.com/Mauwii/azure-pipelines-with-github-repo edit_uri : edit/main/docs/ # Copyright copyright : Copyright &copy; 2022 Matthias Wild # Configuration theme : name : null custom_dir : 'src/mkdocs-material/material' # 404 page static_templates : - 404.html # Necessary for search to work properly include_search_page : false search_index_only : true # Default values, taken from mkdocs_theme.yml language : en features : - content.code.annotate # - content.tabs.link - content.tooltips # - header.autohide - navigation.expand - navigation.indexes - navigation.instant - navigation.sections - navigation.tabs - navigation.tabs.sticky - navigation.top - navigation.tracking - search.highlight - search.share - search.suggest # - toc.follow - toc.integrate palette : - media : '(prefers-color-scheme: light)' primary : blue scheme : default toggle : icon : material/lightbulb name : Switch to dark mode - media : '(prefers-color-scheme: dark)' primary : dark-blue accent : white scheme : slate toggle : icon : material/lightbulb-outline name : Switch to light mode font : text : Roboto code : Roboto Mono favicon : 'assets/favicon.png' icon : logo : 'material/library' admonition : note : octicons/tag-16 abstract : octicons/checklist-16 info : octicons/info-16 tip : octicons/squirrel-16 success : octicons/check-16 question : octicons/question-16 warning : octicons/alert-16 failure : octicons/x-circle-16 danger : octicons/zap-16 bug : octicons/bug-16 example : octicons/beaker-16 quote : octicons/quote-16 # Customization extra : social : - icon : fontawesome/brands/github-alt link : https://github.com/Mauwii - icon : fontawesome/brands/docker link : https://hub.docker.com/r/mauwii/ - icon : fontawesome/brands/keybase link : https://keybase.io/mauwi - icon : material/email-fast link : mailto:mauwii@outlook.de version : provider : mike # Extensions markdown_extensions : - abbr - admonition - attr_list - def_list - footnotes - meta - md_in_html - toc : permalink : true - pymdownx.arithmatex : generic : true - pymdownx.betterem : smart_enable : all - pymdownx.caret - pymdownx.details - pymdownx.emoji : emoji_index : !!python/name:materialx.emoji.twemoji emoji_generator : !!python/name:materialx.emoji.to_svg - pymdownx.highlight : anchor_linenums : true - pymdownx.inlinehilite - pymdownx.keys - pymdownx.magiclink : repo_url_shorthand : true user : 'Mauwii' repo : 'azure-pipelines-with-github-repo' - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences : custom_fences : - name : mermaid class : mermaid format : !!python/name:pymdownx.superfences.fence_code_format - pymdownx.snippets - pymdownx.tabbed : alternate_style : true - pymdownx.tasklist : custom_checkbox : true - pymdownx.tilde - tables # Plugins plugins : - search - git-revision-date - mike","title":"Current Config"},{"location":"#license","text":"License Copyright \u00a9 2022 Matthias Wild Mauwii@outlook.de Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"todo/","text":"Clean up all the mess which has grown over the last weeks of development Documentation \u00b6 Build MkDocs for main branch as well as stable branch, not sure if this will need the mkdocs-plugin mike to work properly or if I can have more Environments in GitHub-Pages (for free...). Currently I am building MkDocs in main Branch as well, but not publishing it, to make sure it is buildable before allowing a PullRequest to be merged. Update Documentation (ongoing ) integrate publish_docs into azure-pipelines.yml update workflow chart and Diagrams update commit flow example Azure-Pipelines \u00b6 use a naming convention maybe even test if it is applied by using kind of RegEx update bicep template add a KeyVault to store: application Insights use the defaults.yaml for configuration relevant things like f.E. default location of pipeline YAMLs or Bicep templates use variables for default parameters in pipeline-templates create branch dependent variable templates (done for main) select correct template by destination branch create bicep templates link secrets between resources (like f.E. AppInsights Instrumentation Key into WebApp-Settings) Maybe unnecessary \u00b6 Overwrite YAML Triggers for Main pipeline (azure-pipeline.yml) to prevent running it from other Branches (still open since unsure if even necessary) Add Check to PR-Validation ,before building the WebApp, to see if the Resources already exist, since keys get read out while building the App, which is failing if they don't exist at all Ideas \u00b6 Since the Human Brain not always works as well as cloud-storage, I will write down some Ideas here. This also has the Advantage that other's could directly correct or improve them, or maybe even take advantage from them as well auto-complete pull requests maybe based upon tags which could be set for successful builds Implement Automation to update submodules add repos to watch as resources trigger a build when defined branch has changes if build is successful, trigger a pipeline to update tested submodule this could then trigger the build of the submodule to staging move pipeline templates so separate Repository as described here create a src older and move submodules of mkdocs-material and django_webapp into it search/replace old file path with the new one","title":"ToDo"},{"location":"todo/#documentation","text":"Build MkDocs for main branch as well as stable branch, not sure if this will need the mkdocs-plugin mike to work properly or if I can have more Environments in GitHub-Pages (for free...). Currently I am building MkDocs in main Branch as well, but not publishing it, to make sure it is buildable before allowing a PullRequest to be merged. Update Documentation (ongoing ) integrate publish_docs into azure-pipelines.yml update workflow chart and Diagrams update commit flow example","title":" Documentation"},{"location":"todo/#azure-pipelines","text":"use a naming convention maybe even test if it is applied by using kind of RegEx update bicep template add a KeyVault to store: application Insights use the defaults.yaml for configuration relevant things like f.E. default location of pipeline YAMLs or Bicep templates use variables for default parameters in pipeline-templates create branch dependent variable templates (done for main) select correct template by destination branch create bicep templates link secrets between resources (like f.E. AppInsights Instrumentation Key into WebApp-Settings)","title":" Azure-Pipelines"},{"location":"todo/#maybe-unnecessary","text":"Overwrite YAML Triggers for Main pipeline (azure-pipeline.yml) to prevent running it from other Branches (still open since unsure if even necessary) Add Check to PR-Validation ,before building the WebApp, to see if the Resources already exist, since keys get read out while building the App, which is failing if they don't exist at all","title":"Maybe unnecessary"},{"location":"todo/#ideas","text":"Since the Human Brain not always works as well as cloud-storage, I will write down some Ideas here. This also has the Advantage that other's could directly correct or improve them, or maybe even take advantage from them as well auto-complete pull requests maybe based upon tags which could be set for successful builds Implement Automation to update submodules add repos to watch as resources trigger a build when defined branch has changes if build is successful, trigger a pipeline to update tested submodule this could then trigger the build of the submodule to staging move pipeline templates so separate Repository as described here create a src older and move submodules of mkdocs-material and django_webapp into it search/replace old file path with the new one","title":" Ideas"},{"location":"reference/","text":"I just added a very small Portion of the original mkdocs-material Documentation to give you an idea what this could look like, but a much better impression as well as up to date Information can be found here . Useful Links \u00b6 MkDocs-Material Documentation \u00b6 For a full list of most recent MkDocs-Material References have a look in the official Documentation . Mermaid Live Editor \u00b6 If you want to get started with Mermaid Diagrams, or already use them for your Project, I recommend to take a look at the Mermaid live Editor , which is pretty helpflull for newbes as well as advanced users. If you want to find out more about how to configure MkDocs-Material to use Diagrams you can do so here .","title":"Reference"},{"location":"reference/#useful-links","text":"","title":"Useful Links"},{"location":"reference/#mkdocs-material-documentation","text":"For a full list of most recent MkDocs-Material References have a look in the official Documentation .","title":"MkDocs-Material Documentation"},{"location":"reference/#mermaid-live-editor","text":"If you want to get started with Mermaid Diagrams, or already use them for your Project, I recommend to take a look at the Mermaid live Editor , which is pretty helpflull for newbes as well as advanced users. If you want to find out more about how to configure MkDocs-Material to use Diagrams you can do so here .","title":"Mermaid Live Editor"},{"location":"reference/diagrams/","text":"Diagrams help to communicate complex relationships and interconnections between different technical components, and are a great addition to project documentation. Material for MkDocs integrates with Mermaid.js , a very popular and flexible solution for drawing diagrams. Usage \u00b6 Using flowcharts \u00b6 Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps: Flow chart ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; Using sequence diagrams \u00b6 Sequence diagrams describe a specific scenario as sequential interactions between multiple objects or actors, including the messages that are exchanged between those actors: Sequence diagram ``` mermaid sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Using state diagrams \u00b6 State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states: State diagram ``` mermaid stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] ``` stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] Using class diagrams \u00b6 Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them: Class diagram ``` mermaid classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } ``` classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } Using entity-relationship diagrams \u00b6 An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge: Entity-relationship diagram ``` mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses Other diagram types \u00b6 Besides the diagram types listed above, Mermaid.js provides support for pie charts , gantt charts , user journeys , git graphs and requirement diagrams , all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js , but we don't consider them a good choice, mostly as they don't work well on mobile.","title":"Diagrams"},{"location":"reference/diagrams/#usage","text":"","title":"Usage"},{"location":"reference/diagrams/#using-flowcharts","text":"Flowcharts are diagrams that represent workflows or processes. The steps are rendered as nodes of various kinds and are connected by edges, describing the necessary order of steps: Flow chart ``` mermaid graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!]; ``` graph LR A[Start] --> B{Error?}; B -->|Yes| C[Hmm...]; C --> D[Debug]; D --> B; B ---->|No| E[Yay!];","title":"Using flowcharts"},{"location":"reference/diagrams/#using-sequence-diagrams","text":"Sequence diagrams describe a specific scenario as sequential interactions between multiple objects or actors, including the messages that are exchanged between those actors: Sequence diagram ``` mermaid sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! ``` sequenceDiagram Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good!","title":"Using sequence diagrams"},{"location":"reference/diagrams/#using-state-diagrams","text":"State diagrams are a great tool to describe the behavior of a system, decomposing it into a finite number of states, and transitions between those states: State diagram ``` mermaid stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*] ``` stateDiagram-v2 state fork_state <<fork>> [*] --> fork_state fork_state --> State2 fork_state --> State3 state join_state <<join>> State2 --> join_state State3 --> join_state join_state --> State4 State4 --> [*]","title":"Using state diagrams"},{"location":"reference/diagrams/#using-class-diagrams","text":"Class diagrams are central to object oriented programing, describing the structure of a system by modelling entities as classes and relationships between them: Class diagram ``` mermaid classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() } ``` classDiagram Person <|-- Student Person <|-- Professor Person : +String name Person : +String phoneNumber Person : +String emailAddress Person: +purchaseParkingPass() Address \"1\" <-- \"0..1\" Person:lives at class Student{ +int studentNumber +int averageMark +isEligibleToEnrol() +getSeminarsTaken() } class Professor{ +int salary } class Address{ +String street +String city +String state +int postalCode +String country -validate() +outputAsLabel() }","title":"Using class diagrams"},{"location":"reference/diagrams/#using-entity-relationship-diagrams","text":"An entity-relationship diagram is composed of entity types and specifies relationships that exist between entities. It describes inter-related things in a specific domain of knowledge: Entity-relationship diagram ``` mermaid erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses ``` erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses","title":"Using entity-relationship diagrams"},{"location":"reference/diagrams/#other-diagram-types","text":"Besides the diagram types listed above, Mermaid.js provides support for pie charts , gantt charts , user journeys , git graphs and requirement diagrams , all of which are not officially supported by Material for MkDocs. Those diagrams should still work as advertised by Mermaid.js , but we don't consider them a good choice, mostly as they don't work well on mobile.","title":"Other diagram types"},{"location":"reference/images/","text":"only-light / only-dark \u00b6 Switch Theme and get amazed","title":"Images"},{"location":"reference/images/#only-light-only-dark","text":"Switch Theme and get amazed","title":"only-light / only-dark"},{"location":"workflow/1-repository/","text":"In this Section you will find Information related to the Workflow of the Repository. Branching Strategy \u00b6 Table \u00b6 Branch name Create From deploy to accept PR from Branch protection rules / other Info main git init staging feature/* issue/* update/* hotfix/* Require linear history Require status checks to pass before merging Require branches to be up to date before merging stable Pull-Request production main hotfix/* feature/* issue/* update/* Head of main test local - must be up to date with main for PR hotfix/* Head of stable test local - Main branch is used as the working branch. To develope new features, create branch from main branch called feature/<jira-id>/<feature-name> for new features, or issue/<jira-id>/<issue-name> when solving a issue. When development of the feature or issue is done, create a pull request to merge it into main branch. When time has come for a release, create a pull request to merge main into stable. For bigger problems, like f.E. a zero-day, create a branch from stable and name it hotfix/<jira-id> and try to fix the issue asap. When done, merge this hotfix back into stable as well as main. Diagrams \u00b6 Small \u00b6 graph LR featureBranch[feature/*<br>issue/*<br>update/*] --> main; main -.-> featureBranch; main --> stable; stable -.-> hotfix; hotfix --> stable & main; Detailed \u00b6 From feature/issue to main \u00b6 graph LR featureBranch[feature/*<br>issue/*<br>update/*] -- Pull Request ---> main; code[\\update<br>Code/] -- Commit Changes --> featureBranch; main -. create branch .-> featureBranch; main -- Trigger Build --> CheckFeature{Built<br>successful}; CheckFeature -- Yes --> mergePR[/merge PR/]; CheckFeature -- No --> TryFixBugsFeature{Try to<br>fix bugs}; mergePR --> deleteFeature; TryFixBugsFeature -- No --> deleteFeature[\\Delete feature/issue branch\\]; TryFixBugsFeature -- Yes --> code; From main to stable \u00b6 graph LR main -- Pull Request ---> stable; stable -- Trigger<br>Build --> validateBuild{Built<br>succesfull}; validateBuild -- Yes --> completePr[/merge PR/]; validateBuild -- No --> createHotfix; completePr --> deployStable[/Deploy to<br>production/]; stable -. create branch .-> createHotfix[create Hotfix]; createHotfix -- fix bugs --> hotfix hotfix -- Pull Request--> main & stable; commit flow example \u00b6 gitGraph commit branch stable branch feature-1 checkout feature-1 commit checkout main merge feature-1 checkout stable merge main checkout main branch feature-2 branch feature-3 checkout feature-2 commit checkout feature-3 commit checkout main merge feature-2 branch feature-4 checkout feature-4 commit checkout stable branch hotfix-1 checkout hotfix-1 commit checkout stable merge hotfix-1 checkout main merge hotfix-1 checkout feature-3 commit checkout main merge feature-3 checkout feature-4 commit checkout main merge feature-4 checkout stable merge main Automation \u00b6 Of course the approach is to have as much automated as possible, which also means that pull-request should in the end get tested and resolved by themselves (...or the help of Azure-Pipelines )","title":"Repository"},{"location":"workflow/1-repository/#branching-strategy","text":"","title":"Branching Strategy"},{"location":"workflow/1-repository/#table","text":"Branch name Create From deploy to accept PR from Branch protection rules / other Info main git init staging feature/* issue/* update/* hotfix/* Require linear history Require status checks to pass before merging Require branches to be up to date before merging stable Pull-Request production main hotfix/* feature/* issue/* update/* Head of main test local - must be up to date with main for PR hotfix/* Head of stable test local - Main branch is used as the working branch. To develope new features, create branch from main branch called feature/<jira-id>/<feature-name> for new features, or issue/<jira-id>/<issue-name> when solving a issue. When development of the feature or issue is done, create a pull request to merge it into main branch. When time has come for a release, create a pull request to merge main into stable. For bigger problems, like f.E. a zero-day, create a branch from stable and name it hotfix/<jira-id> and try to fix the issue asap. When done, merge this hotfix back into stable as well as main.","title":"Table"},{"location":"workflow/1-repository/#diagrams","text":"","title":"Diagrams"},{"location":"workflow/1-repository/#small","text":"graph LR featureBranch[feature/*<br>issue/*<br>update/*] --> main; main -.-> featureBranch; main --> stable; stable -.-> hotfix; hotfix --> stable & main;","title":"Small"},{"location":"workflow/1-repository/#detailed","text":"","title":"Detailed"},{"location":"workflow/1-repository/#from-featureissue-to-main","text":"graph LR featureBranch[feature/*<br>issue/*<br>update/*] -- Pull Request ---> main; code[\\update<br>Code/] -- Commit Changes --> featureBranch; main -. create branch .-> featureBranch; main -- Trigger Build --> CheckFeature{Built<br>successful}; CheckFeature -- Yes --> mergePR[/merge PR/]; CheckFeature -- No --> TryFixBugsFeature{Try to<br>fix bugs}; mergePR --> deleteFeature; TryFixBugsFeature -- No --> deleteFeature[\\Delete feature/issue branch\\]; TryFixBugsFeature -- Yes --> code;","title":"From feature/issue to main"},{"location":"workflow/1-repository/#from-main-to-stable","text":"graph LR main -- Pull Request ---> stable; stable -- Trigger<br>Build --> validateBuild{Built<br>succesfull}; validateBuild -- Yes --> completePr[/merge PR/]; validateBuild -- No --> createHotfix; completePr --> deployStable[/Deploy to<br>production/]; stable -. create branch .-> createHotfix[create Hotfix]; createHotfix -- fix bugs --> hotfix hotfix -- Pull Request--> main & stable;","title":"From main to stable"},{"location":"workflow/1-repository/#commit-flow-example","text":"gitGraph commit branch stable branch feature-1 checkout feature-1 commit checkout main merge feature-1 checkout stable merge main checkout main branch feature-2 branch feature-3 checkout feature-2 commit checkout feature-3 commit checkout main merge feature-2 branch feature-4 checkout feature-4 commit checkout stable branch hotfix-1 checkout hotfix-1 commit checkout stable merge hotfix-1 checkout main merge hotfix-1 checkout feature-3 commit checkout main merge feature-3 checkout feature-4 commit checkout main merge feature-4 checkout stable merge main","title":"commit flow example"},{"location":"workflow/1-repository/#automation","text":"Of course the approach is to have as much automated as possible, which also means that pull-request should in the end get tested and resolved by themselves (...or the help of Azure-Pipelines )","title":"Automation"},{"location":"workflow/2-azure-pipelines/","text":"azure-pipelines.yml \u00b6 This is the YAML File which defined the main Pipeline while this Docs your are reading have been deployed. Most Parts of it are referencing Templates which are located bellow the subfolder /azure-pipelines . I had the Idea to use this folder for pipeline Stage-Templates, then use the azure-pipelines/jobs subfolder for job-templates and finally a subfolder azure-pipelines/jobs/steps for, you guessed it, step-templates. But at the moment I am thinking to have another subfolder-stage azure-pipelines/stages/jobs/steps , and store pipelines directly in azure-pipelines , which atm are stored in azure-pipelines/triggers which feels kind of wrong. azure-pipelines.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 trigger : batch : true branches : include : - refs/heads/main - refs/heads/stable pr : - main resources : repositories : - repository : self endpoint : Mauwii variables : - template : azure-pipelines/variables/default.yml - ${{ if in(variables['Build.SourceBranch'], 'refs/heads/main', 'refs/heads/stable') }} : - template : azure-pipelines/variables/${{ variables['Build.SourceBranchName'] }}.yml parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string default : '$(bicepDir)' - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod default : dev - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string default : '$(resourceGroupName)' - name : azureSubscription displayName : Name of the ARM-Service Connection type : string default : '$(azureSubscription)' - name : location displayName : Location where the Resources will be deployed type : string default : $(location) - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' - name : cleanup displayName : 'Run cleanup stage' type : boolean default : true extends : template : azure-pipelines/stages/main.yml parameters : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} cleanup : ${{ parameters.cleanup }} agentpool : ${{ parameters.agentpool }} main.yml \u00b6 This stage-template contains is defining the complete pipeline. I had it separated from azure-pipelines.yml to be able to run validate_pr.yml (pull request validation) with the same stages than azure-pipelines.yml , but while Writing this, I already get thoughts about a restructure, but would first need to test it out before I start writing documentation for it. In the end it could not work out and everything stays as it is azure-pipelines/main.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string default : IaC/bicep/deploy - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod default : dev - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string default : $(resourceGroupName) - name : azureSubscription displayName : Name of the ARM-Service Connection type : string default : $(azureSubscription) - name : location displayName : Location where the Resources will be deployed to type : string default : 'westeurope' - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' - name : cleanup type : boolean default : false stages : - template : bicep_stage.yml parameters : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} agentpool : ${{ parameters.agentpool }} - ${{ if eq(parameters.cleanup, 'True') }} : - template : cleanup.yml parameters : agentpool : ${{ parameters.agentpool }} resourceGroupName : ${{ parameters.resourceGroupName }} bicep_stage.yml \u00b6 This stage is seperated in two jobs. where the first job is enumerating how often the second job needs to be run. Well, ok, this sounds a bit weird, but the secret is that it is not re-running the second job for x-times, but for every folder found in IaC/bicep/deploy . The steps which will then be done are found in the next section azure-pipelines/bicep_stage.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string - name : azureSubscription displayName : Name of the ARM-Service Connection type : string - name : location displayName : Location where the Resources will be deployed to type : string - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' stages : - stage : bicep displayName : Bicep pool : name : ${{ parameters.agentpool }} jobs : - job : getTemplateFolders displayName : Get Template Folders steps : - task : PowerShell@2 name : mtrx env : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} inputs : targetType : filePath filePath : scripts/New-BicepMatrix.ps1 - job : runner displayName : Test and Deploy dependsOn : getTemplateFolders condition : succeeded() strategy : matrix : $[ dependencies.getTemplateFolders.outputs['mtrx.legs'] ] maxParallel : 1 steps : - template : jobs/steps/bicep_steps.yml parameters : bicepDir : $(bicepDir) bicepTemplateDir : $(bicepTemplateDir) bicepParameter : $(bicepParameter) resourceGroupName : $(resourceGroupName) azureSubscription : $(azureSubscription) location : $(location) bicep_steps.yml \u00b6 This step-template will: validate that the bicep is buildable (which is converting it to a ARM Template) create a resource group (no problem if called more than once and all runs belong to the same RG) do some verifications if the bicep is valid and deployable If conditions are met, it is calling another template to finally deploy the resources to Azure Resource Manager. azure-pipelines/jobs/steps/bicep_steps.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 parameters : - name : bicepDir type : string default : $(bicepDir) - name : bicepTemplateDir type : string default : $(bicepTemplateDir) - name : bicepParameter type : string default : $(bicepParameter) - name : resourceGroupName type : string default : $(resourceGroupName) - name : azureSubscription type : string default : $(azureSubscription) - name : location type : string default : $(location) steps : - script : az bicep build --file main.bicep displayName : Run Bicep Linter name : LintBicepCode workingDirectory : $(bicepDir)/$(bicepTemplateDir) - template : create_resourceGroup.yml parameters : resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} - task : AzureCLI@2 name : RunPreflightValidation condition : succeeded() displayName : Run preflight validation inputs : azureSubscription : ${{ parameters.azureSubscription }} workingDirectory : $(bicepDir)/$(bicepTemplateDir) scriptType : bash scriptLocation : inlineScript inlineScript : | az deployment group validate \\ --resource-group ${{ parameters.resourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json - task : AzureCLI@2 name : RunWhatIf displayName : Run what-if inputs : azureSubscription : ${{ parameters.azureSubscription }} workingDirectory : $(bicepDir)/$(bicepTemplateDir) scriptType : bash scriptLocation : inlineScript inlineScript : | az deployment group what-if \\ --resource-group ${{ parameters.resourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json - task : AzureCLI@2 name : DeployBicepFile condition : and(succeeded(), in('True', variables['isMain'], variables['isStable'])) displayName : Deploy Bicep Template inputs : azureSubscription : ${{ parameters.azureSubscription }} scriptType : bash scriptLocation : inlineScript workingDirectory : $(bicepDir)/$(bicepTemplateDir) inlineScript : | az deployment group create \\ --name $(Build.BuildNumber) \\ --resource-group ${{ parameters.ResourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json create_resourceGroup.yml \u00b6 Well, I think the headline has already explained what this step is all about azure-pipelines/jobs/steps/create_resourceGroup.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 parameters : - name : resourceGroupName displayName : Resourcegroup Name type : string - name : azureSubscription displayName : Azure Service Connection type : string - name : location displayName : Resourcegroup Location type : string steps : - task : AzureCLI@2 condition : succeeded() displayName : Create RG ${{ parameters.resourceGroupName }} continueOnError : true inputs : azureSubscription : ${{ parameters.azureSubscription }} scriptType : bash scriptLocation : inlineScript inlineScript : | az group create \\ --name ${{ parameters.resourceGroupName }} \\ --location ${{ parameters.location }} mkdocs-material \u00b6 This pipeline is validating, building and deploying the documentation you are just looking at Validation is done with building the docs, if there is no error I suggest that everything will be fine after it is just a static website. The Deployment step will only appear when the pipeline get run from main branch. azure-pipelines/mkdocs-material.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 trigger : branches : include : - refs/heads/stable - refs/heads/main - feature/* - issue/* - update/* paths : include : - docs - mkdocs.yml - src/requirements-mkdocs-material.txt - src/mkdocs-material - azure-pipelines/mkdocs-material.yml - azure-pipelines/stages/jobs/steps/build_mkdocs.yml pr : - main parameters : - name : pythonVersion displayName : Python Version to use when building MkDocs-Material type : string values : - '3.9' - '3.10' default : '3.10' - name : mkdocsSiteDir displayName : Name of the Directory where MkDocs will be built to type : string default : 'site' - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' variables : - template : variables/default.yml jobs : - job : displayName : MkDocs-Material pool : name : ${{ parameters.agentpool }} steps : - template : stages/jobs/steps/checkout_submodules.yml parameters : submodule : 'src/mkdocs-material' checkoutSelf : true - template : stages/jobs/steps/build_mkdocs.yml parameters : pythonVersion : '${{ parameters.pythonVersion }}' mkdocsSiteDir : '${{ parameters.mkdocsSiteDir }}' - ${{ if in(variables['Build.SourceBranchName'], 'Main', 'Stable') }} : - script : | git config user.name \"${BUILD_SOURCEVERSIONAUTHOR:-mauwii}\" git config user.email \"${BUILD_REQUESTEDFOREMAIL:-mauwii@mauwii.onmicrosoft.com}\" mike delete \"$BUILD_SOURCEBRANCHNAME\" deleteVersion=$(mike list | grep -m 1 ${BUILD_SOURCEBRANCHNAME}) mike delete $deleteVersion mike deploy -t \"$BUILD_SOURCEBRANCHNAME\" --update-aliases \"$BUILD_SOURCEBRANCHNAME.$BUILD_BUILDID\" \"$BUILD_SOURCEBRANCHNAME\" mike set-default \"$BUILD_SOURCEBRANCHNAME\" git push origin gh-pages displayName : 'update gh-pages' build_mkdocs.yml \u00b6 azure-pipelines/stages/jobs/steps/build_mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 parameters : - name : pythonVersion displayName : Python Version to use values : - '3.9' - '3.10' type : string default : $(pythonVersion) - name : mkdocsSiteDir type : string default : 'site' steps : - task : UsePythonVersion@0 displayName : 'Use Python ${{ parameters.pythonVersion }}' inputs : versionSpec : '${{ parameters.pythonVersion }}' addToPath : true - script : pip install --upgrade pip wheel setuptools displayName : update tools - script : npm install --no-package-lock displayName : npm install workingDirectory : src/mkdocs-material - script : pip install -e src/mkdocs-material displayName : install MkDocs-Material - script : pip install -r requirements.txt displayName : install requirements - script : mkdocs build --site-dir ${{ parameters.mkdocsSiteDir }} --verbose displayName : build docs devopsbuildagent.yml \u00b6 This Pipeline will build a docker image of a DevOps-Agent, if you want to find out more about it's features, look here azure-pipelines/devopsbuildagent.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 trigger : branches : include : - refs/heads/main - update/* - feature/* - issue/* paths : include : - azure-pipelines/devopsbuildagent.yml - azure-pipelines/stages/jobs/build_devopsbuildagent_job.yml - src/DevOpsBuildAgent pr : none variables : - name : baseOS value : 'linux' - name : baseDistro value : 'ubuntu' - name : baseVersion value : '20.04' - name : dockerRegistry value : 'docker.io' - name : dockerhubuser value : 'mauwii' - name : dockerimage value : 'devopsbuildagent' parameters : - name : matrix type : object displayName : Object which defines the matrix strategy default : amd64 : baseArch : 'amd64' targetProc : 'x64' arm64v8 : baseArch : 'arm64v8' targetProc : 'arm64' - name : maxParallelJobs type : number displayName : Defines how many Jobs can be running in parallel by the matrix strategy default : 2 stages : - stage : build jobs : - template : stages/jobs/build_devopsbuildagent_job.yml parameters : matrix : ${{ parameters.matrix }} maxParallelJobs : ${{ parameters.maxParallelJobs }} - stage : manifest dependsOn : build jobs : - template : stages/jobs/pushManifest_job.yml parameters : matrix : ${{ parameters.matrix }} maxParallelJobs : ${{ parameters.maxParallelJobs }} cleanup_automation.yml \u00b6 This Pipeline will delete Resources in Subscriptions of the used Service Principal automatically. It differs between Resources which where available before and after a initial Date, which will have a defined range of days from creation before they will be deleted. While date is not reach, it will set a Tag on the Resource with the deletion date (which is just used for information). After the Resource has reached the defined age it will be deleted. Necessary to use this Pipeline is a Service Principal with permission to delete Resources and Resource Locks. azure-pipelines/cleanup_automation.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 trigger : none pr : none schedules : - cron : \"0 0 * * *\" displayName : Daily cleanup branches : include : - main steps : - task : AzurePowerShell@5 inputs : azureSubscription : 'mngmtgrp001' ScriptType : 'FilePath' azurePowerShellVersion : 'LatestVersion' pwsh : true ScriptPath : 'scripts/cleanupautomation.ps1' env : ApplicationId : $(ApplicationId) ClientSecret : $(ClientSecret) SpTenantId : $(TenantId) scripts/cleanupautomation.ps1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 param ( [Switch] $LocalTest ) # Connect to Azure-CLI as Service Principal [void] ( az login ` - -service-principal ` -u $env:ApplicationId ` -p $env:ClientSecret ` -t $env:SpTenantId ) # Get Current UTC-Time $CurrentUTCtime = ( Get-Date ). ToUniversalTime () # Set Initial Date $InitialDate = ( Get-Date -Year 2022 -Month 06 -Day 15 ). ToUniversalTime () # Days until Resources get deleted $NewerResourceDays = 7 $OlderResourceDays = 14 # Initialize Variables to count existing and deleted Resources/RGs $AllAzRgCount = 0 $DeletedAzRgCount = 0 $AllAzResourceCount = 0 $DeletedAzResourceCount = 0 # Function to Print Information function Write-Info { param ( [System.String] $Title , [System.String] $Value , [Switch] $InitialNewLine , [Switch] $FinalNewLine ) $Title = \"${Title}: \" $Value = \" `t ${Value}\" if ( $InitialNewLine ) { $Title = \" `n ${Title}\" } if ( $FinalNewLine ) { $Value = \"${Value} `n \" } Write-Host ` -ForegroundColor Cyan ` -NoNewline ` $Title Write-Host $Value } # Iterate over subscriptions foreach ( $AzSubscription in Get-AzSubscription ) { # Set Context to current Subscription [void] ( Set-AzContext ` -Subscription $AzSubscription . Id ) [void] ( az account set ` - -subscription $AzSubscription . Id ) # Get Resourcegroups of current Context $AzResourceGroups = Get-AzResourceGroup # Add Number of ResourceGroups to AllAzRg $AllAzRgCount += $AzResourceGroups . Length # Get Number of Resources in current Context $AzResourceCount = ( Get-AzResource ). Length # Add Number of Resources in Subscription to AllAzResourceCount $AllAzResourceCount += $AzResourceCount # Write Info to Host about current Subscription Write-Info ` -InitialNewLine ` -Title \"Subscription Name\" ` -Value $AzSubscription . Name Write-Info ` -Title \"Resourcegroups\" ` -Value $AzResourceGroups . Length Write-Info ` -Title \"Resource Count\" ` -Value \"$AzResourceCount\" ` -FinalNewLine # Iterate over Resource Groups foreach ( $AzResourceGroup in $AzResourceGroups ) { # Get Resources in current Resource Group $AzResources = Get-AzResource ` -ResourceGroupName $AzResourceGroup . ResourceGroupName # Write Info to Host about Current Resource Group Write-Info ` -Title \"Resource Group\" ` -Value $AzResourceGroup . ResourceGroupName Write-Info ` -Title \"Resource Count\" ` -Value $AzResources . Length # Iterate over Resources in current Resource Group foreach ( $AzResource in $AzResources ) { # Get Current Resource Creation Time $AzCurrentResource = ( az resource list ` - -location $AzResource . Location ` - -name $AzResource . Name ` - -query \"[].{Name:name, RG:resourceGroup, Created:createdTime, Changed:changedTime}\" ` -o json | ConvertFrom-Json ) # Check if Resource was created before or after initial date to give devs more days to react on older resources if (( $AzCurrentResource . Created ). ToUniversalTime () -gt $InitialDate ) { $DaysToDelete = $NewerResourceDays - ( $CurrentUTCtime - ( $AzCurrentResource . Created ). ToUniversalTime ()). Days } else { $DaysToDelete = $OlderResourceDays - ( $CurrentUTCtime - $InitialDate ). Days } # Add/update Tag \"DeletionDate\" of Resource, or Delete it if defined age has been reached if ( $DaysToDelete -gt 0 ) { # Write Info to Host when Resource will be deleted Write-Host ` -NoNewline ` $AzCurrentResource . Name , \"will be deleted in $DaysToDelete \" if ( $DaysToDelete -gt 1 ) { Write-Host \"Days\" } else { Write-Host \"Day\" } # Set DeletionDate $DeletionDate = $CurrentUTCtime . AddDays ( $DaysToDelete ) # Create Tag $Tag = @{ \"DeletionDate\" = \"$DeletionDate UTC\" ; } [void] ( Update-AzTag ` -ResourceId $AzResource . Id ` -Tag $Tag ` -Operation Merge ` -WhatIf : $LocalTest ) } else { # Get Resource Lock $AzResourceLock = Get-AzResourceLock ` -ResourceName $AzResource . Name ` -ResourceType $AzResource . Type ` -ResourceGroupName $AzResource . ResourceGroupName # Remove Resource Lock if existing if ( $AzResourceLock ) { Write-Host \"Deleting Resource Lock of $( $AzResource . Name ) \" [void] ( Remove-AzResourceLock ` -LockId $AzResourceLock . LockId ` -Force : $true ` -WhatIf : $LocalTest ) } # Remove Resource $RmResource = Remove-AzResource ` -ResourceId $AzResource . Id ` -WhatIf : $LocalTest ` -ErrorAction : SilentlyContinue ` -Force : $true # Write Info and Increment Deleted Resource Count if succeeded if ( $RmResource ) { Write-Host \"Deleted $( $AzResource . Name ) \" $DeletedAzResourceCount ++ } else { Write-Host \"Could not delete $( $AzResource . Name ) \" } } } # Get Resourcecount in current Resource Group $AzRgResourceCount = ( Get-AzResource ` -ResourceGroupName $AzResourceGroup . ResourceGroupName ). Length # Delete Resourcegroup if empty if ( $AzRgResourceCount -eq 0 ) { [void] ( Remove-AzResourceGroup ` -Name $AzResourceGroup . ResourceGroupName ` -Force : $true ` -WhatIf : $LocalTest ) # Write Info to Host that ResourceGroup was deleted Write-Info ` -Title \"Deleted Resourcegroup\" ` -Value $AzResourceGroup . ResourceGroupName ` -FinalNewLine # Increment DeletedAzRgCount $DeletedAzRgCount ++ } else { # Write Info to Host that ResourceGroup is done Write-Info ` -Title \"Resourcegroup Done\" ` -Value $AzResourceGroup . ResourceGroupName ` -FinalNewLine } } # Write Info to Host that Subscription is done Write-Info ` -Title \"Subscription Done\" ` -Value $AzSubscription . Name ` -FinalNewLine } # Write Info to Host about Resource-Counts Write-Info ` -Title \"Deleted RGs\" ` -Value \" `t $DeletedAzRgCount of $AllAzRgCount\" Write-Info ` -Title \"Deleted resources\" ` -Value \"$DeletedAzResourceCount of $AllAzResourceCount\"","title":"Azure-Pipelines"},{"location":"workflow/2-azure-pipelines/#azure-pipelinesyml","text":"This is the YAML File which defined the main Pipeline while this Docs your are reading have been deployed. Most Parts of it are referencing Templates which are located bellow the subfolder /azure-pipelines . I had the Idea to use this folder for pipeline Stage-Templates, then use the azure-pipelines/jobs subfolder for job-templates and finally a subfolder azure-pipelines/jobs/steps for, you guessed it, step-templates. But at the moment I am thinking to have another subfolder-stage azure-pipelines/stages/jobs/steps , and store pipelines directly in azure-pipelines , which atm are stored in azure-pipelines/triggers which feels kind of wrong. azure-pipelines.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 trigger : batch : true branches : include : - refs/heads/main - refs/heads/stable pr : - main resources : repositories : - repository : self endpoint : Mauwii variables : - template : azure-pipelines/variables/default.yml - ${{ if in(variables['Build.SourceBranch'], 'refs/heads/main', 'refs/heads/stable') }} : - template : azure-pipelines/variables/${{ variables['Build.SourceBranchName'] }}.yml parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string default : '$(bicepDir)' - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod default : dev - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string default : '$(resourceGroupName)' - name : azureSubscription displayName : Name of the ARM-Service Connection type : string default : '$(azureSubscription)' - name : location displayName : Location where the Resources will be deployed type : string default : $(location) - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' - name : cleanup displayName : 'Run cleanup stage' type : boolean default : true extends : template : azure-pipelines/stages/main.yml parameters : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} cleanup : ${{ parameters.cleanup }} agentpool : ${{ parameters.agentpool }}","title":"azure-pipelines.yml"},{"location":"workflow/2-azure-pipelines/#mainyml","text":"This stage-template contains is defining the complete pipeline. I had it separated from azure-pipelines.yml to be able to run validate_pr.yml (pull request validation) with the same stages than azure-pipelines.yml , but while Writing this, I already get thoughts about a restructure, but would first need to test it out before I start writing documentation for it. In the end it could not work out and everything stays as it is azure-pipelines/main.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string default : IaC/bicep/deploy - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod default : dev - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string default : $(resourceGroupName) - name : azureSubscription displayName : Name of the ARM-Service Connection type : string default : $(azureSubscription) - name : location displayName : Location where the Resources will be deployed to type : string default : 'westeurope' - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' - name : cleanup type : boolean default : false stages : - template : bicep_stage.yml parameters : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} agentpool : ${{ parameters.agentpool }} - ${{ if eq(parameters.cleanup, 'True') }} : - template : cleanup.yml parameters : agentpool : ${{ parameters.agentpool }} resourceGroupName : ${{ parameters.resourceGroupName }}","title":"main.yml"},{"location":"workflow/2-azure-pipelines/#bicep_stageyml","text":"This stage is seperated in two jobs. where the first job is enumerating how often the second job needs to be run. Well, ok, this sounds a bit weird, but the secret is that it is not re-running the second job for x-times, but for every folder found in IaC/bicep/deploy . The steps which will then be done are found in the next section azure-pipelines/bicep_stage.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 parameters : - name : bicepDir displayName : Directory containing Folders with Bicep Templates type : string - name : bicepParameter displayName : Used in some templates to change Resource Name or other variables type : string values : - dev - stg - prod - name : resourceGroupName displayName : Name of the Resource Group where templates will be deployed to type : string - name : azureSubscription displayName : Name of the ARM-Service Connection type : string - name : location displayName : Location where the Resources will be deployed to type : string - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' stages : - stage : bicep displayName : Bicep pool : name : ${{ parameters.agentpool }} jobs : - job : getTemplateFolders displayName : Get Template Folders steps : - task : PowerShell@2 name : mtrx env : bicepDir : ${{ parameters.bicepDir }} bicepParameter : ${{ parameters.bicepParameter }} resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} inputs : targetType : filePath filePath : scripts/New-BicepMatrix.ps1 - job : runner displayName : Test and Deploy dependsOn : getTemplateFolders condition : succeeded() strategy : matrix : $[ dependencies.getTemplateFolders.outputs['mtrx.legs'] ] maxParallel : 1 steps : - template : jobs/steps/bicep_steps.yml parameters : bicepDir : $(bicepDir) bicepTemplateDir : $(bicepTemplateDir) bicepParameter : $(bicepParameter) resourceGroupName : $(resourceGroupName) azureSubscription : $(azureSubscription) location : $(location)","title":"bicep_stage.yml"},{"location":"workflow/2-azure-pipelines/#bicep_stepsyml","text":"This step-template will: validate that the bicep is buildable (which is converting it to a ARM Template) create a resource group (no problem if called more than once and all runs belong to the same RG) do some verifications if the bicep is valid and deployable If conditions are met, it is calling another template to finally deploy the resources to Azure Resource Manager. azure-pipelines/jobs/steps/bicep_steps.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 parameters : - name : bicepDir type : string default : $(bicepDir) - name : bicepTemplateDir type : string default : $(bicepTemplateDir) - name : bicepParameter type : string default : $(bicepParameter) - name : resourceGroupName type : string default : $(resourceGroupName) - name : azureSubscription type : string default : $(azureSubscription) - name : location type : string default : $(location) steps : - script : az bicep build --file main.bicep displayName : Run Bicep Linter name : LintBicepCode workingDirectory : $(bicepDir)/$(bicepTemplateDir) - template : create_resourceGroup.yml parameters : resourceGroupName : ${{ parameters.resourceGroupName }} azureSubscription : ${{ parameters.azureSubscription }} location : ${{ parameters.location }} - task : AzureCLI@2 name : RunPreflightValidation condition : succeeded() displayName : Run preflight validation inputs : azureSubscription : ${{ parameters.azureSubscription }} workingDirectory : $(bicepDir)/$(bicepTemplateDir) scriptType : bash scriptLocation : inlineScript inlineScript : | az deployment group validate \\ --resource-group ${{ parameters.resourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json - task : AzureCLI@2 name : RunWhatIf displayName : Run what-if inputs : azureSubscription : ${{ parameters.azureSubscription }} workingDirectory : $(bicepDir)/$(bicepTemplateDir) scriptType : bash scriptLocation : inlineScript inlineScript : | az deployment group what-if \\ --resource-group ${{ parameters.resourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json - task : AzureCLI@2 name : DeployBicepFile condition : and(succeeded(), in('True', variables['isMain'], variables['isStable'])) displayName : Deploy Bicep Template inputs : azureSubscription : ${{ parameters.azureSubscription }} scriptType : bash scriptLocation : inlineScript workingDirectory : $(bicepDir)/$(bicepTemplateDir) inlineScript : | az deployment group create \\ --name $(Build.BuildNumber) \\ --resource-group ${{ parameters.ResourceGroupName }} \\ --template-file main.bicep \\ --parameters @main.parameters.${{parameters.bicepParameter}}.json","title":"bicep_steps.yml"},{"location":"workflow/2-azure-pipelines/#create_resourcegroupyml","text":"Well, I think the headline has already explained what this step is all about azure-pipelines/jobs/steps/create_resourceGroup.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 parameters : - name : resourceGroupName displayName : Resourcegroup Name type : string - name : azureSubscription displayName : Azure Service Connection type : string - name : location displayName : Resourcegroup Location type : string steps : - task : AzureCLI@2 condition : succeeded() displayName : Create RG ${{ parameters.resourceGroupName }} continueOnError : true inputs : azureSubscription : ${{ parameters.azureSubscription }} scriptType : bash scriptLocation : inlineScript inlineScript : | az group create \\ --name ${{ parameters.resourceGroupName }} \\ --location ${{ parameters.location }}","title":"create_resourceGroup.yml"},{"location":"workflow/2-azure-pipelines/#mkdocs-material","text":"This pipeline is validating, building and deploying the documentation you are just looking at Validation is done with building the docs, if there is no error I suggest that everything will be fine after it is just a static website. The Deployment step will only appear when the pipeline get run from main branch. azure-pipelines/mkdocs-material.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 trigger : branches : include : - refs/heads/stable - refs/heads/main - feature/* - issue/* - update/* paths : include : - docs - mkdocs.yml - src/requirements-mkdocs-material.txt - src/mkdocs-material - azure-pipelines/mkdocs-material.yml - azure-pipelines/stages/jobs/steps/build_mkdocs.yml pr : - main parameters : - name : pythonVersion displayName : Python Version to use when building MkDocs-Material type : string values : - '3.9' - '3.10' default : '3.10' - name : mkdocsSiteDir displayName : Name of the Directory where MkDocs will be built to type : string default : 'site' - name : agentpool displayName : Agent-Pool to be used values : - 'Azure Pipelines' - 'local' default : 'Azure Pipelines' variables : - template : variables/default.yml jobs : - job : displayName : MkDocs-Material pool : name : ${{ parameters.agentpool }} steps : - template : stages/jobs/steps/checkout_submodules.yml parameters : submodule : 'src/mkdocs-material' checkoutSelf : true - template : stages/jobs/steps/build_mkdocs.yml parameters : pythonVersion : '${{ parameters.pythonVersion }}' mkdocsSiteDir : '${{ parameters.mkdocsSiteDir }}' - ${{ if in(variables['Build.SourceBranchName'], 'Main', 'Stable') }} : - script : | git config user.name \"${BUILD_SOURCEVERSIONAUTHOR:-mauwii}\" git config user.email \"${BUILD_REQUESTEDFOREMAIL:-mauwii@mauwii.onmicrosoft.com}\" mike delete \"$BUILD_SOURCEBRANCHNAME\" deleteVersion=$(mike list | grep -m 1 ${BUILD_SOURCEBRANCHNAME}) mike delete $deleteVersion mike deploy -t \"$BUILD_SOURCEBRANCHNAME\" --update-aliases \"$BUILD_SOURCEBRANCHNAME.$BUILD_BUILDID\" \"$BUILD_SOURCEBRANCHNAME\" mike set-default \"$BUILD_SOURCEBRANCHNAME\" git push origin gh-pages displayName : 'update gh-pages'","title":"mkdocs-material"},{"location":"workflow/2-azure-pipelines/#build_mkdocsyml","text":"azure-pipelines/stages/jobs/steps/build_mkdocs.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 parameters : - name : pythonVersion displayName : Python Version to use values : - '3.9' - '3.10' type : string default : $(pythonVersion) - name : mkdocsSiteDir type : string default : 'site' steps : - task : UsePythonVersion@0 displayName : 'Use Python ${{ parameters.pythonVersion }}' inputs : versionSpec : '${{ parameters.pythonVersion }}' addToPath : true - script : pip install --upgrade pip wheel setuptools displayName : update tools - script : npm install --no-package-lock displayName : npm install workingDirectory : src/mkdocs-material - script : pip install -e src/mkdocs-material displayName : install MkDocs-Material - script : pip install -r requirements.txt displayName : install requirements - script : mkdocs build --site-dir ${{ parameters.mkdocsSiteDir }} --verbose displayName : build docs","title":"build_mkdocs.yml"},{"location":"workflow/2-azure-pipelines/#devopsbuildagentyml","text":"This Pipeline will build a docker image of a DevOps-Agent, if you want to find out more about it's features, look here azure-pipelines/devopsbuildagent.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 trigger : branches : include : - refs/heads/main - update/* - feature/* - issue/* paths : include : - azure-pipelines/devopsbuildagent.yml - azure-pipelines/stages/jobs/build_devopsbuildagent_job.yml - src/DevOpsBuildAgent pr : none variables : - name : baseOS value : 'linux' - name : baseDistro value : 'ubuntu' - name : baseVersion value : '20.04' - name : dockerRegistry value : 'docker.io' - name : dockerhubuser value : 'mauwii' - name : dockerimage value : 'devopsbuildagent' parameters : - name : matrix type : object displayName : Object which defines the matrix strategy default : amd64 : baseArch : 'amd64' targetProc : 'x64' arm64v8 : baseArch : 'arm64v8' targetProc : 'arm64' - name : maxParallelJobs type : number displayName : Defines how many Jobs can be running in parallel by the matrix strategy default : 2 stages : - stage : build jobs : - template : stages/jobs/build_devopsbuildagent_job.yml parameters : matrix : ${{ parameters.matrix }} maxParallelJobs : ${{ parameters.maxParallelJobs }} - stage : manifest dependsOn : build jobs : - template : stages/jobs/pushManifest_job.yml parameters : matrix : ${{ parameters.matrix }} maxParallelJobs : ${{ parameters.maxParallelJobs }}","title":"devopsbuildagent.yml"},{"location":"workflow/2-azure-pipelines/#cleanup_automationyml","text":"This Pipeline will delete Resources in Subscriptions of the used Service Principal automatically. It differs between Resources which where available before and after a initial Date, which will have a defined range of days from creation before they will be deleted. While date is not reach, it will set a Tag on the Resource with the deletion date (which is just used for information). After the Resource has reached the defined age it will be deleted. Necessary to use this Pipeline is a Service Principal with permission to delete Resources and Resource Locks. azure-pipelines/cleanup_automation.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 trigger : none pr : none schedules : - cron : \"0 0 * * *\" displayName : Daily cleanup branches : include : - main steps : - task : AzurePowerShell@5 inputs : azureSubscription : 'mngmtgrp001' ScriptType : 'FilePath' azurePowerShellVersion : 'LatestVersion' pwsh : true ScriptPath : 'scripts/cleanupautomation.ps1' env : ApplicationId : $(ApplicationId) ClientSecret : $(ClientSecret) SpTenantId : $(TenantId) scripts/cleanupautomation.ps1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 param ( [Switch] $LocalTest ) # Connect to Azure-CLI as Service Principal [void] ( az login ` - -service-principal ` -u $env:ApplicationId ` -p $env:ClientSecret ` -t $env:SpTenantId ) # Get Current UTC-Time $CurrentUTCtime = ( Get-Date ). ToUniversalTime () # Set Initial Date $InitialDate = ( Get-Date -Year 2022 -Month 06 -Day 15 ). ToUniversalTime () # Days until Resources get deleted $NewerResourceDays = 7 $OlderResourceDays = 14 # Initialize Variables to count existing and deleted Resources/RGs $AllAzRgCount = 0 $DeletedAzRgCount = 0 $AllAzResourceCount = 0 $DeletedAzResourceCount = 0 # Function to Print Information function Write-Info { param ( [System.String] $Title , [System.String] $Value , [Switch] $InitialNewLine , [Switch] $FinalNewLine ) $Title = \"${Title}: \" $Value = \" `t ${Value}\" if ( $InitialNewLine ) { $Title = \" `n ${Title}\" } if ( $FinalNewLine ) { $Value = \"${Value} `n \" } Write-Host ` -ForegroundColor Cyan ` -NoNewline ` $Title Write-Host $Value } # Iterate over subscriptions foreach ( $AzSubscription in Get-AzSubscription ) { # Set Context to current Subscription [void] ( Set-AzContext ` -Subscription $AzSubscription . Id ) [void] ( az account set ` - -subscription $AzSubscription . Id ) # Get Resourcegroups of current Context $AzResourceGroups = Get-AzResourceGroup # Add Number of ResourceGroups to AllAzRg $AllAzRgCount += $AzResourceGroups . Length # Get Number of Resources in current Context $AzResourceCount = ( Get-AzResource ). Length # Add Number of Resources in Subscription to AllAzResourceCount $AllAzResourceCount += $AzResourceCount # Write Info to Host about current Subscription Write-Info ` -InitialNewLine ` -Title \"Subscription Name\" ` -Value $AzSubscription . Name Write-Info ` -Title \"Resourcegroups\" ` -Value $AzResourceGroups . Length Write-Info ` -Title \"Resource Count\" ` -Value \"$AzResourceCount\" ` -FinalNewLine # Iterate over Resource Groups foreach ( $AzResourceGroup in $AzResourceGroups ) { # Get Resources in current Resource Group $AzResources = Get-AzResource ` -ResourceGroupName $AzResourceGroup . ResourceGroupName # Write Info to Host about Current Resource Group Write-Info ` -Title \"Resource Group\" ` -Value $AzResourceGroup . ResourceGroupName Write-Info ` -Title \"Resource Count\" ` -Value $AzResources . Length # Iterate over Resources in current Resource Group foreach ( $AzResource in $AzResources ) { # Get Current Resource Creation Time $AzCurrentResource = ( az resource list ` - -location $AzResource . Location ` - -name $AzResource . Name ` - -query \"[].{Name:name, RG:resourceGroup, Created:createdTime, Changed:changedTime}\" ` -o json | ConvertFrom-Json ) # Check if Resource was created before or after initial date to give devs more days to react on older resources if (( $AzCurrentResource . Created ). ToUniversalTime () -gt $InitialDate ) { $DaysToDelete = $NewerResourceDays - ( $CurrentUTCtime - ( $AzCurrentResource . Created ). ToUniversalTime ()). Days } else { $DaysToDelete = $OlderResourceDays - ( $CurrentUTCtime - $InitialDate ). Days } # Add/update Tag \"DeletionDate\" of Resource, or Delete it if defined age has been reached if ( $DaysToDelete -gt 0 ) { # Write Info to Host when Resource will be deleted Write-Host ` -NoNewline ` $AzCurrentResource . Name , \"will be deleted in $DaysToDelete \" if ( $DaysToDelete -gt 1 ) { Write-Host \"Days\" } else { Write-Host \"Day\" } # Set DeletionDate $DeletionDate = $CurrentUTCtime . AddDays ( $DaysToDelete ) # Create Tag $Tag = @{ \"DeletionDate\" = \"$DeletionDate UTC\" ; } [void] ( Update-AzTag ` -ResourceId $AzResource . Id ` -Tag $Tag ` -Operation Merge ` -WhatIf : $LocalTest ) } else { # Get Resource Lock $AzResourceLock = Get-AzResourceLock ` -ResourceName $AzResource . Name ` -ResourceType $AzResource . Type ` -ResourceGroupName $AzResource . ResourceGroupName # Remove Resource Lock if existing if ( $AzResourceLock ) { Write-Host \"Deleting Resource Lock of $( $AzResource . Name ) \" [void] ( Remove-AzResourceLock ` -LockId $AzResourceLock . LockId ` -Force : $true ` -WhatIf : $LocalTest ) } # Remove Resource $RmResource = Remove-AzResource ` -ResourceId $AzResource . Id ` -WhatIf : $LocalTest ` -ErrorAction : SilentlyContinue ` -Force : $true # Write Info and Increment Deleted Resource Count if succeeded if ( $RmResource ) { Write-Host \"Deleted $( $AzResource . Name ) \" $DeletedAzResourceCount ++ } else { Write-Host \"Could not delete $( $AzResource . Name ) \" } } } # Get Resourcecount in current Resource Group $AzRgResourceCount = ( Get-AzResource ` -ResourceGroupName $AzResourceGroup . ResourceGroupName ). Length # Delete Resourcegroup if empty if ( $AzRgResourceCount -eq 0 ) { [void] ( Remove-AzResourceGroup ` -Name $AzResourceGroup . ResourceGroupName ` -Force : $true ` -WhatIf : $LocalTest ) # Write Info to Host that ResourceGroup was deleted Write-Info ` -Title \"Deleted Resourcegroup\" ` -Value $AzResourceGroup . ResourceGroupName ` -FinalNewLine # Increment DeletedAzRgCount $DeletedAzRgCount ++ } else { # Write Info to Host that ResourceGroup is done Write-Info ` -Title \"Resourcegroup Done\" ` -Value $AzResourceGroup . ResourceGroupName ` -FinalNewLine } } # Write Info to Host that Subscription is done Write-Info ` -Title \"Subscription Done\" ` -Value $AzSubscription . Name ` -FinalNewLine } # Write Info to Host about Resource-Counts Write-Info ` -Title \"Deleted RGs\" ` -Value \" `t $DeletedAzRgCount of $AllAzRgCount\" Write-Info ` -Title \"Deleted resources\" ` -Value \"$DeletedAzResourceCount of $AllAzResourceCount\"","title":"cleanup_automation.yml"}]}